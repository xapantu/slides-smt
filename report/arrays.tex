% !TEX root = report.tex
% !TEX program = pdflatex

In this section, we describe an extension of the previous algorithm to
deal with arrays. The syntax for $K$ arrays $a_1, \ldots, a_K$ is
described in Figure \ref{syntaxarray}. It is important to note that
arrays are only accessed on the quantified variable, and not on a
general term built on this variable (such as $k + 1$, or a nested
array read). Removing this syntax restriction leads to an undecidable
array theory fragment, as stated in
\cite{bradley2006s}, even for small additions to the
fragment.

In additions to the restriction already described in the first section, it is also necessary for the
formulas inside counting constraints to not have atoms with both an array read $a_i[x]$ and $x$,
that is, atoms like $a_i[x] = x$ are forbidden.

\begin{figure}[h]
\begin{grammar}

<formulas> $\phi$ ::= $\phi$ $\land$ $\phi$
\alt $\phi$ $\lor$ $\phi$
\alt $\lnot$ $\phi$
\alt $\langle atoms\rangle$ of $\qflia$
\alt $c = \cterm{\phi(k, a_1[k], \ldots, a_K[k]}$

\end{grammar}
\caption{Array Extension}
\label{syntaxarray}
\end{figure}


An array has a size, which is an arithmetic variable of the theory
$\qflia$. This is similar to the model checker \textsc{Arca}
\cite{AlbertiGP16} (with the subtle difference that
different arrays can have different size) but unlike \textsc{Cubicle}
\cite{ConchonGKMZ12}, whose fragment does not
provide a syntax to express an array length. In the context of fault
tolerant systems, this is an important detail, as we typically want to
specify that at most one third of the components are faulty.

The elements of the arrays can be of any sort, but as we are working with
$\qflia$, we assume they belong to $\mathbb{Z}$\footnote{But the algorithm does
not rely on this, so it would not change anything if we used a richer theory with
more sorts.}.

As soon as there is an array term in the counting constraints, the
cardinality can no longer be infinite, as the array can only be accessed
on a finite interval, that is, term $a[k]$ implicitly implies that $0 \le k < N$ if $a$ is an array of size $N$.

It may be interesting to have array reads outside of the counting
constraints. However, they can be rewritten as counting constraints, as in
\cite{bradley2006s} or
\cite{AlbertiGP16}: $a[v]$ can be replaced by a new variable $y$ with the additional constraint:
\begin{equation}
\sharp\{k\mid k = v \land a[k] = y\} = 1
\end{equation}

In the implementation section, we explain
how this algorithm can be changed to work with the usual theory of arrays of an
SMT solver, which is more efficient.

\subsection{Decision Procedure}

\subsubsection{Overview}

The algorithm to solve counting constraints with arrays is mostly the
same as the one to solve pure arithmetic counting constraints. While we do the interval analysis,
we must save the constraints on the arrays. In the end, those constraints must be checked for
satisfiability and whether they conflict in case there are several constraints
for the same interval. Pseudocode of the algorithm is show in Algorithm
\ref{arrayalgo}.

During my internship, I experimented several possible algorithms to
manipulate those constraints. The algorithm I describe here might seem a
bit brutal as it extensively rely on the SMT solver, but it
worked better than the other attempts, probably because a modern SMT
solver can be much more efficient than a less optimized specialized
algorithm.

\begin{algorithm}[h]
\caption{Satisfiability of a formula with arrays and counting constraints}
\begin{algorithmic}[1]
\Procedure{\checkcsat}{F}
\Require $F \equiv G(\vec{x}, \vec{c}) \land \bigwedge_{i=1}^n c_i =
\cterm{\phi_i(k, \vec{a}[k], \vec{x}, \vec{c})}$.
\State $\assert(G)$
\While{$\mathcal{M} = \checksat()$}
    \LineComment Interpret constraints in $\mathcal{M}$ and collect assumptions.
    \State $\push()$
    \ForAll{ $i \in [1..n]$}
        \LineComment Compute assumptions and domains for $i$-th constraint
        \State $\langle A_i, D_i \rangle \gets \interpret(\mathcal{M}, c_i, \phi_i)$
        \State $\assert(A_i)$
        \If{$D_i$ is infinite}
			\State $\pop()$
            \State \Call{assert}{$\lnot A_i$}
            \State \Call{continue}{}
        \EndIf
    \EndFor
    \State \Call{slice}{$(D_i)_i$}
    \State \Call{partition}{$(D_i)_i$}
    \State \Comment{$v_\alpha$ is a variable corresponding to a constraint
	associated with $D_i$}
    \State \Call{assert}{$\bigwedge\limits_{i=1}^n c_i = \sum\limits_{[a, b] \in S_i} \sum\limits_{\alpha} v_{\alpha}$}
    \State \Call{assert-constraints}{$(D_i)_i$}
    \LineComment Check if the assumptions and counting constraints are consistent.
    \If {$\mathcal{M}_\sharp = \checksat()$}
        \State \Return{$\langle \sat, \mathcal{M}_\sharp \rangle$}
    \EndIf
    \State $\pop()$
    \State $\assert(\lnot A_1 \vee \ldots \vee \lnot A_n)$
\EndWhile
\State \Return{\unsat}
\EndProcedure
\end{algorithmic}
\label{arrayalgo}
\end{algorithm}

\newpage

\begin{example}
Consider the following formula

\begin{multline*}
\overbrace{N > 0 \land c_1 > N/2 \land c_2 > N/2}^G \\
\land c_1 = \cterm{\underbrace{0 \le k < N \land a[k] > 0}_{\phi_1}} \\
\land c_2 = \cterm{\underbrace{0 \le k < N \land a[k] \leq 0}_{\phi_2}}\enspace.
\end{multline*}

\begin{itemize}
\item First we ask \solver for a model of $G$, it gives $\mathcal{M} = \{ N
\mapsto 1, c_1 \mapsto 1, c_2 \mapsto 1 \}$.
\item For both counting terms, domains are computed and are composed of a single
interval: $[0, N)$ associated with $a[\cdot] > 0$ and $[0, N)$ associated with
$a[\cdot] \leq 0$. Here, slicing do not change the domain,
as there is a single interval. Partitioning creates 4 constraint: $a[\cdot] >
0 \land a[\cdot] \leq 0$, $a[\cdot] > 0 \land \lnot (a[\cdot] \leq 0)$,
$\lnot(a[\cdot] > 0) \lnot a[\cdot] \leq 0$, $\lnot (a[\cdot] > 0) \land \lnot
(a[\cdot] \leq 0)$.
\item New variables (positive integers) are created for every constraint (there is a single
interval): $v_1$, $v_2$, $v_3$, $v_4$. We assert
that $c_1 = v_1 + v_2$ and $c_2 = v_1 + v_3$. We also assert that $N = v_1 + v_2
+ v_3 + v_4$.
\item Then we ask \solver for a model, and it says \texttt{unsat}: it is not
possible to have $c_1Â > N/2$, $c_2 > N/2$ and $N = v_1 + v_2 + v_3$.
\end{itemize}

\end{example}

\subsubsection{Constraints on the Arrays}

\begin{definition}[Array Constraint]

An array constraint is a first order, quantifier free, formula whose
free variables are the free variables of the formula and the variables
$a_1[\cdot], \ldots, a_k[\cdot]$.

\label{array}

\end{definition}


\begin{definition}[Domain]

A domain is a finite set of symbolic intervals (definition
\ref{symbolic}), every one of them associated with an array constraint
(definition \ref{array}).

\label{domain}

\end{definition}

An arithmetic domain (definition \ref{arithmetic}) can then be seen as a
domain whose every symbolic interval is associated with the constraint
\texttt{true}.

Generating an array constraint for every symbolic interval is done while we compute those symbolic
intervals. The rules for conjunction and negation are updated accordingly. For instance, when we
look at a conjunction and produce the intersection of every symbolic interval in both domains, we
associate to this intersection the conjunction of the array constraints of both intervals.

There are additional base cases, which are the literals with $a_1[x], \ldots, a_k[x]$. For those
case, we return the domain with one symbolic interval, $(-\infty, +\infty)$,
associated with the
constraint which is the literal, and to an empty assumptions set.

\subsubsection{Checking the Constraints on the Arrays}

\ifthenelse{0=1}{}{
We now want to generate a set of constraints that are equivalent to the
satisfiability of the formula and the counting constraints.

We start from a set of $l$ domains (one for every counting
constraints) and generate a set of arithmetic constraints.

\paragraph{Slice}\label{slice}

The first operation we do is what we call \emph{slicing}. It means that
the domains must be transformed so as they all have the same intervals.
In practice, we are looking for a subdivision of $[A, B)$ (where $A$
is the lower bound of every array index and $B$ the upper bound) which
can be used to express every domains. This is a simple operation that I
do not detail here, intuitively every bound of the intervals is
collected, then they are split into equality classes and ordered (in the
meantime the set of assumptions may be made bigger).

\paragraph{Partition}\label{partition}

At this point we have a set of domains who all have the same intervals
but different array constraints associated with them. For an interval
$I$, we consider every constraints associated with it, i.e.,
$\phi_1, \ldots, \phi_l$. From these one we can create a set of formula
$\psi_1, \ldots, \psi_{l'}$ which are a
partition\footnote{A partition is a set of formula $\psi_1, \ldots, \psi_n$ such as $\psi_1 \lor \ldots \lor \psi_n \equiv \top$ but $\forall i, j. \; \psi_i \land \psi_j \equiv \bot$.}.
There can be at most $2^l$ formula, but of course that can be
dramatically reduced in practice with heuristics such as memoization and
inclusion detection.

\paragraph{Arithmetic Constraints}\label{arithmetic-constraints}

$I = [a, b)$ is supposed to be a finite interval (or it means that the
array is accessed on an infinite intervals, which is not supposed to
happen), so, it has a length $b - a$. As $\psi_1, \ldots, \psi_{l'}$ is a
partition, it holds that
$b - a = \sum\limits_{i = 1}^{l'} \sharp\{x \ |\ \psi_i(a_1[x], \ldots, a_n[x])\}$.We
create a new variable $v_i$ (such as $0 \le v_i$) for every
$\sharp\{x\ |\ \psi_i(a_1[x], \ldots, a_n[x]\}$ and adds the constraint
$b - a = \sum v_i$ to the solver. As long as every $\psi_i$ is
satisfiable, then we can build arrays that satisfy
$v_i = \sharp\{x\ |\ \psi_i(a_1[x], \ldots, a_n[x]\}$. Hence, we must assert
$v_i > 0 \implies \psi_i(a_{i, 1}, \ldots, a_{i, n})$ (with new variables
$a_{i, 1}, \ldots, a_{i, n})$.


Then, we have to link the $v_i$ to the original counting term. We assert that
every counting term is equal to the sum of the $v_i$ that are derived from it.

}

\subsection{Implementation}

\paragraph{Theory of arrays} The previous algorithm transforms every array read and write into an
array constraint. This is not very efficient, because the underlying SMT
solver has no clue regarding the consistency of the values it provides
for an array read. That's why it is interesting to change this algorithm
to make it work with a usual array theory of an SMT solver. The
algorithm then has to take into account the decision that the SMT solver
when it outputs the constraints, so as the result is consistent
(i.e., the arrays are not defined twice).

Unfortunately, as our algorithm operates outside of the solver, the
interactions they can have are quite limited. Thus, it is important to
understand how the theory of arrays is usually implemented to make it
work with the counting constraints algorithm described in the last
section.

A state of the art implementation of the theory of arrays is described
in \cite{de2009generalized}. More specifically, it
explains how works the SMT solver Z3.

The only two operations on arrays are \texttt{select} and
\texttt{store}. \texttt{(select\ a\ x)} access the array $a$ at index
$x$ (also written $a[x]$), while \texttt{(store\ a\ x\ b)} creates a
new array whose elements are the same as $a$ but for $x$, where it
is set to $b$ (also written $a[x \leftarrow b]$). The two axioms of this theory are:

\begin{subequations}
    \begin{align}
        \forall a:(\sigma \implies \tau), i:\sigma, v:\tau\, .\, store(a, i, v)[i] = v
        \\
        \forall a:(\sigma \implies \tau), i:\sigma, j:\sigma\, .\, i \neq j \implies store(a, i, v)[j] = a[j]
    \end{align}


    Additionnaly, there is the extensionality axiom:

    \begin{align}
        \forall a:(\sigma \implies \tau), b:(\sigma \implies \tau)\, .\, a \neq b \iff \exists i\: a[i] \implies a[i] \neq b[i]
    \end{align}
\end{subequations}

For the first two axioms, it is clear that the SMT solver is only going
to take decisions about terms index which appear inside a \texttt{store}
and a \texttt{select}. An equality might introduce additional indexes to
make two arrays different. That's why an array extracted from a model of
an SMT solver always follows the same pattern: special values are
defined for a finite number of terms (an over-approximation of those
terms can be obtained by looking at the formula), and then a default
value. And the default value does not matter, as long as there is no
equality.

\begin{example}
We consider the formula:
\begin{equation*}
a[z] < 0 \land a = b[z \leftarrow -5] \land a[z] \neq b[y]
\end{equation*}

The solver \solver gives a model of this formula in which $y$ is different from
$z$, $a[z] = -5$, $a[y] = b[y] = 0$ and the rest of the arrays is equal to $0$
(the default value). This example illustrate the fact that there is no need to
specify values for indexes that do not appear in the formula.
\end{example}


Thus, to ensure the consistency of the counting constraint algorithm and
the SMT solver decisions about arrays, we only have to take into account
the value at those index terms, and array equality if needed.

The first problem can be solved by tracking those index terms, then
looking at the model which slice they belong to, and group them by
slice. Then, for every array constraint $\phi_\alpha$ of this slice,
some new clauses must be sent to the solver to ensure the consistency of
this values decided by the SMT solver with the number of $x$ which
satisfies $\phi_\alpha$

The equality between two arrays must also be tracked, they must be taken
into account when the arithmetic constraints are expressed at the end of
the algorithm by adding new array constraints. In my implementation, some heuristics (such as
substitution of the arrays when there is equality) are also used.

However, for model checking, one way of the extensionality axiom can be dropped. If $a \neq b$, it
does not have to reflect in the existence of an $i$ such as $a[i] \neq b[i]$. In our example, an
equality is always produced by an assignment, and that is why $\lnot (a = b)$ is better interpreted
as an undefined behavior than a disequality. My tests showed that making equality not extensional
(and thus avoiding an extra array constraint) did not provide a significant performance gain, that
is why my implementation has an extensional equality, as it would be confusing for no gain.


\paragraph{Complexity}

Our algorithm works by assuming a set of assumptions and checking that
cardinality values that they imply is consistent. The worst case for the
assumptions is to be a total ordering over every integer variable and an
assumptions on every atom of the formula. The number of total ordering
over $n$ variables is
$n!$\footnote{More than that if we take into account the case where two variables are equal.},
which makes the algorithm unpractical if there is not enough constraints
on those variables in the formula.

That is why it would be interesting to have a better explanation of why
it is not \texttt{sat} and not only learn that the formula is
\texttt{unsat} with this particular ordering. That requires an
explanation from the SMT solver and a better integration with both the
arithmetic theory and the arrays theory.

Furthermore, partial assumptions are sufficient to compute the bounds of
a cardinality, and may also be sufficient to detect an inconsistency
earlier in the solving of the formula, hence avoiding useless
computations. Some work for abstract sets has already be done in this
direction \cite{cardinalityset}.

The way the algorithm works is not very different from the way a theory
is usually modeled in DPLL(T) based solver, the main differences being
that it has nested formula and has to interact with the array and
arithmetic theories. So, adapting it to be just another theory in a
solver may be worthwhile.
